test:
  normalize: True
  data_config:
    dataset_config:
      data_path: "/home/manolotis/sandbox/robustness_benchmark/multipathPP/data/prerendered/test/"
      lstm_input_data: [ "xy", "yaw", "speed", "width", "length", "valid" ]
      lstm_input_data_diff: [ "xy", "yaw", "speed", "valid" ]
      mask_history: False
      n_shards: 1
    dataloader_config:
      batch_size: 8
      shuffle: False
      num_workers: 8
  output_config:
    visualize: False
    out_path: "/home/manolotis/sandbox/robustness_benchmark/multipathPP/predictions/"
    viz_path: "/home/manolotis/sandbox/robustness_benchmark/multipathPP/plots/predictions/"


model:
#  name: "final_RoP_Cov_Single_lr4e-4__65c803f"
  name: "final_RoP_Cov_Single__0f1746c"
  path: "/home/manolotis/sandbox/robustness_benchmark/multipathPP/trained_models/"
  n_trajectories: 6
  size: 640
  make_em: False
  multiple_predictions: False

  agent_mcg_linear:
    layers: [ 24, 32, 64, 128 ]
    pre_activation: False
    pre_batchnorm: False
    batchnorm: False

  interaction_mcg_linear:
    layers: [ 24, 32, 64, 128 ]
    pre_activation: False
    pre_batchnorm: False
    batchnorm: False

  agent_history_encoder:
    position_lstm_config:
      input_size: 13
      hidden_size: 64
    position_diff_lstm_config:
      input_size: 11
      hidden_size: 64
    position_mcg_config:
      agg_mode: "max"
      running_mean_mode: "real"
      alpha: 0.1
      beta: 0.9
      n_blocks: 5
      identity_c_mlp: True
      block:
        c_bias: True
        mlp:
          n_layers: 3
          n_in: 128
          n_out: 128
          bias: True
          batchnorm: False
          dropout: False

  interaction_history_encoder:
    position_lstm_config:
      input_size: 13
      hidden_size: 64
    position_diff_lstm_config:
      input_size: 11
      hidden_size: 64
    position_mcg_config:
      block:
        c_bias: True
        mlp:
          n_layers: 3
          n_in: 128
          n_out: 128
          bias: True
          batchnorm: False
          dropout: False
      agg_mode: "max"
      running_mean_mode: "real"
      alpha: 0.1
      beta: 0.9
      n_blocks: 5
      identity_c_mlp: True

  polyline_encoder:
    layers: [ 27, 32, 64, 128 ]
    pre_activation: False
    pre_batchnorm: False
    batchnorm: False

  history_mcg_encoder:
    block:
      c_bias: True
      mlp:
        n_layers: 3
        n_in: 256
        n_out: 256
        bias: True
        batchnorm: False
        dropout: False
    agg_mode: "max"
    running_mean_mode: "real"
    alpha: 0.1
    beta: 0.9
    n_blocks: 5
    identity_c_mlp: True

  interaction_mcg_encoder:
    block:
      c_bias: True
      mlp:
        n_layers: 3
        n_in: 256
        n_out: 256
        bias: True
        batchnorm: False
        dropout: False
    agg_mode: "max"
    running_mean_mode: "real"
    alpha: 0.1
    beta: 0.9
    n_blocks: 5
    identity_c_mlp: False

  roadgraph_mcg_encoder:
    block:
      c_bias: True
      mlp:
        n_layers: 3
        n_in: 128
        n_out: 128
        bias: True
        batchnorm: False
        dropout: False
    agg_mode: "max"
    running_mean_mode: "real"
    alpha: 0.1
    beta: 0.9
    n_blocks: 5
    identity_c_mlp: False

  agent_and_interaction_linear:
    layers: [ 512, 256, 128 ]
    pre_activation: True
    pre_batchnorm: False
    batchnorm: False

  decoder_handler_config:
    n_decoders: 1
    return_embedding: False
    decoder_config:
      trainable_cov: True
      size: 640
      n_trajectories: 6
      mcg_predictor:
        block:
          c_bias: True
          mlp:
            n_layers: 3
            n_in: 640
            n_out: 640
            bias: True
            batchnorm: False
            dropout: False
        agg_mode: "max"
        running_mean_mode: "real"
        alpha: 0.1
        beta: 0.9
        n_blocks: 5
        identity_c_mlp: False
      DECODER:
        layers: [ 640, 512, 401 ]
        pre_activation: True
        pre_batchnorm: False
        batchnorm: False

  final_decoder:
    trainable_cov: True
    size: 640
    return_embedding: False
    n_trajectories: 6
    mcg_predictor:
      block:
        c_bias: True
        mlp:
          n_layers: 3
          n_in: 640
          n_out: 640
          bias: True
          batchnorm: False
          dropout: False
      agg_mode: "max"
      running_mean_mode: "real"
      alpha: 0.1
      beta: 0.9
      n_blocks: 5
      identity_c_mlp: False
    DECODER:
      layers: [ 640, 512, 401 ]
      pre_activation: True
      pre_batchnorm: False
      batchnorm: False

  mha_decoder: True
